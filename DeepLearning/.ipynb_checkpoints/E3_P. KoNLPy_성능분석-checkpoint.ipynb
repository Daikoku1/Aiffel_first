{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import os\n",
    "from konlpy.tag import Hannanum, Mecab, Kkma, Komoran, Okt\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>파주시청. 사진제공=파주시 파주시청. 사진제공=파주시\\n\\n[파주=파이낸셜뉴스 강근...</td>\n",
       "      <td>사회</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>동영상 뉴스\\n\\n이천 물류창고 화재 발화지점으로 지목된 지하 2층에서 산소절단기의...</td>\n",
       "      <td>사회</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>황범순 의정부시 부시장 을지대학교 의정부캠퍼스 및 부속병원 공사현장 안전점검. 사진...</td>\n",
       "      <td>사회</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>귀갓길 여성을 쫓아가 성범죄를 시도한 20대 남성이 구속됐습니다.서울 강남경찰서는 ...</td>\n",
       "      <td>사회</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(서울=연합뉴스) 대한약사회가 6일부터 코로나바이러스 감염증 대응 체계를 '사회적 ...</td>\n",
       "      <td>사회</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news code\n",
       "0  파주시청. 사진제공=파주시 파주시청. 사진제공=파주시\\n\\n[파주=파이낸셜뉴스 강근...   사회\n",
       "1  동영상 뉴스\\n\\n이천 물류창고 화재 발화지점으로 지목된 지하 2층에서 산소절단기의...   사회\n",
       "2  황범순 의정부시 부시장 을지대학교 의정부캠퍼스 및 부속병원 공사현장 안전점검. 사진...   사회\n",
       "3  귀갓길 여성을 쫓아가 성범죄를 시도한 20대 남성이 구속됐습니다.서울 강남경찰서는 ...   사회\n",
       "4  (서울=연합뉴스) 대한약사회가 6일부터 코로나바이러스 감염증 대응 체계를 '사회적 ...   사회"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "csv_path = os.getenv(\"HOME\") + \"/news_crawler/news_data.csv\"\n",
    "df = pd.read_table(csv_path, sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       파주시청 사진제공파주시 파주시청 사진제공파주시파주파이낸셜뉴스 강근주 기자 파주시는 ...\n",
       "1       동영상 뉴스이천 물류창고 화재 발화지점으로 지목된 지하 층에서 산소절단기의 산소 공...\n",
       "2       황범순 의정부시 부시장 을지대학교 의정부캠퍼스 및 부속병원 공사현장 안전점검 사진제...\n",
       "3       귀갓길 여성을 쫓아가 성범죄를 시도한 대 남성이 구속됐습니다서울 강남경찰서는 강간상...\n",
       "4       서울연합뉴스 대한약사회가 일부터 코로나바이러스 감염증 대응 체계를 사회적 거리두기에...\n",
       "                              ...                        \n",
       "5119    신종 코로나바이러스 감염증코로나 사태 이후 가정의 달 월에도 언택트비대면 신풍속도가...\n",
       "5120    는 소비자로부터 월 이용료 만만원을 받고 초고속 인터넷을 제공한다 그런 브로드밴드가...\n",
       "5121    머리를 긁고 있는 오랑우탄 몸을 긁는 행동을 따라 하는 것은 부정적 감정과 관련이 ...\n",
       "5122    가 오는 일 정식 출시하는 스마트폰 벨벳이 사실상 공짜폰이 될 전망이다 단말기 가격...\n",
       "5123    이미지제공게티이미지뱅크 이미지제공게티이미지뱅크  전자신문  전자신문인터넷 무단전재 ...\n",
       "Name: news, Length: 5124, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정규표현식을 사용하여 한글만 사용\n",
    "df['news'] = df['news'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "df['news']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복 샘플 제거\n",
    "df.drop_duplicates(subset=['news'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 처리\n",
    "stopwords = ['에','는','은','을','했','에게','있','이','의','하','한','다','과','때문','할','수','무단','따른','및','금지','전재','경향신문','기자','는데','가','등','들','파이낸셜','저작','등','뉴스']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이즈 성능 비교를 위한 토크나이즈 설정\n",
    "Mecab_t = Mecab()\n",
    "Hannanum_t = Hannanum()\n",
    "Kkma_t = Kkma()\n",
    "Komoran_t = Komoran(userdic='/tmp/dic.txt')\n",
    "Okt_t = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(tokenizer, data):\n",
    "  text_data = []\n",
    "  for sentence in data:\n",
    "    temp_data = tokenizer.morphs(sentence) \n",
    "    temp_data = [word for word in temp_data if not word in stopwords] \n",
    "    text_data.append(temp_data)\n",
    "\n",
    "  text_data = list(map(' '.join, text_data))\n",
    "\n",
    "  return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mecab</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hannanum</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kkma</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Komoran</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Okt</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         time precision recall   f1\n",
       "Mecab     NaN       NaN    NaN  NaN\n",
       "Hannanum  NaN       NaN    NaN  NaN\n",
       "Kkma      NaN       NaN    NaN  NaN\n",
       "Komoran   NaN       NaN    NaN  NaN\n",
       "Okt       NaN       NaN    NaN  NaN"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 토크나이즈 성능 비교를 위한 토크나이즈 설정\n",
    "# Mecab_t = Mecab()\n",
    "# hannanum_t = Hannanum()\n",
    "# kkma_t = Kkma()\n",
    "# komoran_t = Komoran(userdic='/tmp/dic.txt')\n",
    "# okt_t = Okt()\n",
    "result = pd.DataFrame( index = ['Mecab', 'Hannanum', 'Kkma', 'Komoran', 'Okt'], columns = ['time', 'precision', 'recall', 'f1'])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.90      0.74      0.81       236\n",
      "          사회       0.79      0.91      0.85       422\n",
      "       생활/문화       0.81      0.76      0.79       341\n",
      "\n",
      "    accuracy                           0.82       999\n",
      "   macro avg       0.83      0.80      0.81       999\n",
      "weighted avg       0.82      0.82      0.82       999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prev = time.time()\n",
    "text_data = preprocessing(Mecab_t, df['news'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_data, df['code'], random_state = 0)\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "y_pred = clf.predict(tfidf_vectorizer(X_test))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "result.loc['Mecab','time'] = time.time() - prev\n",
    "result.loc['Mecab','precision'] = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "result.loc['Mecab','recall'] = metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "result.loc['Mecab','f1'] = metrics.f1_score(y_test, y_pred, average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.90      0.64      0.75       236\n",
      "          사회       0.79      0.91      0.85       422\n",
      "       생활/문화       0.79      0.79      0.79       341\n",
      "\n",
      "    accuracy                           0.81       999\n",
      "   macro avg       0.83      0.78      0.80       999\n",
      "weighted avg       0.82      0.81      0.81       999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prev = time.time()\n",
    "text_data = preprocessing(Hannanum_t, df['news'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_data, df['code'], random_state = 0)\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "y_pred = clf.predict(tfidf_vectorizer(X_test))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "result['Hannanum','time'] = time.time() - prev\n",
    "result['Hannanum','precision'] = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "result['Hannanum','recall'] = metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "result['Hannanum','f1'] = metrics.f1_score(y_test, y_pred, average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.90      0.75      0.82       236\n",
      "          사회       0.80      0.91      0.85       422\n",
      "       생활/문화       0.81      0.77      0.79       341\n",
      "\n",
      "    accuracy                           0.82       999\n",
      "   macro avg       0.84      0.81      0.82       999\n",
      "weighted avg       0.83      0.82      0.82       999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prev = time.time()\n",
    "text_data = preprocessing(Kkma_t, df['news'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_data, df['code'], random_state = 0)\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "y_pred = clf.predict(tfidf_vectorizer(X_test))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "result.loc['Kkma','time'] = time.time() - prev\n",
    "result.loc['Kkma','precision'] = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "result.loc['Kkma','recall'] = metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "result.loc['Kkma','f1'] = metrics.f1_score(y_test, y_pred, average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.90      0.74      0.81       236\n",
      "          사회       0.80      0.91      0.85       422\n",
      "       생활/문화       0.81      0.77      0.79       341\n",
      "\n",
      "    accuracy                           0.82       999\n",
      "   macro avg       0.83      0.81      0.82       999\n",
      "weighted avg       0.83      0.82      0.82       999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prev = time.time()\n",
    "text_data = preprocessing(Komoran_t, df['news'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_data, df['code'], random_state = 0)\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "y_pred = clf.predict(tfidf_vectorizer(X_test))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "result.loc['Komoran','time'] = time.time() - prev\n",
    "result.loc['Komoran','precision'] = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "result.loc['Komoran','recall'] = metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "result.loc['Komoran','f1'] = metrics.f1_score(y_test, y_pred, average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.91      0.70      0.79       236\n",
      "          사회       0.78      0.93      0.85       422\n",
      "       생활/문화       0.83      0.76      0.79       341\n",
      "\n",
      "    accuracy                           0.82       999\n",
      "   macro avg       0.84      0.80      0.81       999\n",
      "weighted avg       0.83      0.82      0.82       999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prev = time.time()\n",
    "text_data = preprocessing(Okt_t, df['news'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_data, df['code'], random_state = 0)\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "y_pred = clf.predict(tfidf_vectorizer(X_test))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "result.loc['Okt','time'] = time.time() - prev\n",
    "result.loc['Okt','precision'] = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "result.loc['Okt','recall'] = metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "result.loc['Okt','f1'] = metrics.f1_score(y_test, y_pred, average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mecab</th>\n",
       "      <td>6.05368</td>\n",
       "      <td>0.823619</td>\n",
       "      <td>0.818819</td>\n",
       "      <td>0.817515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hannanum</th>\n",
       "      <td>163.272</td>\n",
       "      <td>0.816591</td>\n",
       "      <td>0.808809</td>\n",
       "      <td>0.805673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kkma</th>\n",
       "      <td>1220.94</td>\n",
       "      <td>0.828254</td>\n",
       "      <td>0.823824</td>\n",
       "      <td>0.822678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Komoran</th>\n",
       "      <td>78.5188</td>\n",
       "      <td>0.825295</td>\n",
       "      <td>0.820821</td>\n",
       "      <td>0.81943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Okt</th>\n",
       "      <td>180.024</td>\n",
       "      <td>0.826798</td>\n",
       "      <td>0.817818</td>\n",
       "      <td>0.815507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             time precision    recall        f1\n",
       "Mecab     6.05368  0.823619  0.818819  0.817515\n",
       "Hannanum  163.272  0.816591  0.808809  0.805673\n",
       "Kkma      1220.94  0.828254  0.823824  0.822678\n",
       "Komoran   78.5188  0.825295  0.820821   0.81943\n",
       "Okt       180.024  0.826798  0.817818  0.815507"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "형태소 분석기에 따른 성능 변화\n",
    "======================\n",
    "- 형태소분석기의 종류에 따른 accuracy는 오차범위 내에서 비슷한 수준임\n",
    "- 다만, 시간 효율적인 측면에서 Mecab의 효율성이 압도적이며, Komoran 역시 나머지 분석기에 비해 빠른 속도를 보임\n",
    "- Kkma 분석기가 오차범위 내에서 가장 높은 정확도를 보여주나, 처리 속도가 크게 늦기 때문에 효율적이지 못함\n",
    "\n",
    "- 데이터 관점\n",
    "    - 분석기 종류에 상관없이 IT분야의 데이터는 precision에 비해 recall값이 많이 낮으며, 사회분야의 데이터는 반대의 경향성을 보임\n",
    "    - 이는 TF-IDF 분류의 특성상 특정 분야에서만 자주 쓰이는 token이 많을수록 정확도가 높아지는 현상 때문이다.\n",
    "    - 반대로 사회 분야는 많은 분야를 포괄적으로 다루기 때문에 사회 뉴스에서만 빈출되는 단어가 다른 분야에 비해 적어 정확도가 낮아지는 것임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
